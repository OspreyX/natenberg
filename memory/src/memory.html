<html>
	<head>
		<title>Memory Barriers and the JVM</title>
		<style>
			.code{
				background-color: #CCCCCC;
				padding: 10px
			}
		</style>
	</head>
	<body>
		<h1>Memory Barriers and the JVM</h1>
		<p>
			This is a crash course in memory barriers and the JVM.  Memory barriers are 
			a class of processor instructions that impact the performance and
			determinism of any multi-threaded program.  This is not an article about mutual exclusion or atomic 
			operations per se.  Memory barriers are used to achieve an equally important element of 
			concurrent programming called visibility.
			We'll look at several concurrency constructs in Java and observe how 
			the JVM uses memory barriers to honor some guarantees of the java memory model.
		</p>
		<h3>What are Memory Barriers?</h3>
		<p>
			Memory barriers are processor instructions used to apply ordering limitations on memory 
			operations.  This has large consequences and a little background on hardware is in order.
		</p>
		<p>
			The costs of memory latency have pushed processors to reorder and cache memory operations.
			A trip to main memory can cost in the neighborhood of 250 clock cycles on modern systems.
			Processors use caching to decrease latency costs of memory operations by orders of magnitude.  
			These caches are write-back, not write-through.
			This means the value of a write operation does not immediately have to be written all the way 
			out to main memory.
			The processor instead places this operation in a buffer and is now obligated to perform this operation at a later time.
			These buffers are often misunderstood as queues. They are not.  
			The operations that accumulate in memory operation buffers are not necessarily performed in the order in which 
			they arrive.  This is usually a good thing because it opens the door to many optimization opportunities.  
		</p>
		<p>
			Combining these optimizations with symmetric multi-processing and shared mutable state is a nightmare.
			Programs can behave non-deterministically when memory operations on shared mutable state are re-ordered.  
			It is possible for a thread to write values that become visible to another thread in an order that is inconsistent 
			with the order in which they were written.
			A good program prevents this problem using memory barriers at the right times.
			A memory barrier instructs the processor to serialize pending memory operations.
			This temporarily closes the door to many opportunities for optimization, sacrificing performance and simplicity for correctness.
			<span style="font-weight:bold; color:red"> <br/>TODO: some say 'flushing' the buffer instead of just 'serializing' it.  
			Are there actual instructions on some hardware that can force a flush?</span>
		</p>
		<h3>Examples</h3>
		<p>
			The JVM translates language level concurrency primitives into memory barriers.  
			Let's look at three simple Java programs and learn by example.
			In each example you will notice seemingly pointless for loops in the source code.  
			Ignore these.  These are only used to trigger JIT compilation.
			The assembly instructions produced by these compilations are what's important.
			A debug version of the JVM can be used to obtain the generated instructions for each Java program.  
			The following works for Linux.  Sun 
			<a target="new" href="http://download.java.net/jdk6/binaries/">has installers</a> for Solaris or Windows
			as well.
		</p>
		<div class="code">
			$ wget http://www.java.net/download/jdk6/6u18/promoted/b05/binaries/jdk-6u18-ea-bin-b05-linux-i586-debug-18_nov_2009.jar<br/>
			$ java -jar jdk-6u18-ea-bin-b05-linux-i586-debug-18_nov_2009.jar<br/>
		</div>
		<p>
			A disassembler plugin is required also. The Kenai project <a href="http://kenai.com/projects/base-hsdis/downloads" target="new">has binaries</a>
			for Solaris, Linux and BSD.  The <a href="http://hg.openjdk.java.net/jdk7/hotspot/hotspot/file/tip/src/share/tools/hsdis/" target="new">hsdis</a>
			plugin is an alternative that can be built from source for Windows. 
		</p>
		<div class="code">
			$ wget http://kenai.com/projects/base-hsdis/downloads/download/linux-hsdis-i386.so<br/>
			$ cp linux-hsdis-i386.so /usr/lib/jvm/java-6-openjdk/jre/lib/i386/server/<br/>
			$ cp linux-hsdis-i386.so /usr/lib/jvm/java-6-openjdk/jre/lib/i386/client/<br/>
		</div>
		<p>
			Our first example is the WriterReader class.
		</p>
		<pre>
	class WriterReader{
	
	  static volatile int shared = 0;
	
	  public static void main(String[] _){
	    Thread writer = new Thread(){
	      public void run(){
	        for(int i = 0; i < 10000; i++)
	          set(i);
	      }
	    };
	    Thread reader = new Thread(){
	      public void run(){
	        for(int i = 0; i < 10000; i++)
	          get();
	      }
	    };
	    writer.start();
	    reader.start(); 
	  }
	
	  static void set(int newValue){ shared = newValue; }
	  
	  static int get(){ return shared; }
	}
		</pre>
		<p>
			The main method of this class creates two threads.  The writer thread writes to a static volatile variable.
			The reader thread reads this variable.  The following command give us a peek at the assembly instructions for this program.  
			Notice how the CompileCommand option is used to filter these instructions down to just those for the static set method.
		</p>
		<div class="code">		
			$ java -XX:+UnlockDiagnosticVMOptions -XX:PrintAssemblyOptions=hsdis-print-bytes -XX:CompileCommand=print,WriterReader.set WriterReader
		</div>
		<p>
			The set method translates to the instructions found between push and pop.
		</p>
		<pre>
  1: push   %ebp               ;...55
  2: mov    %esp,%ebp          ;...8bec
  3: sub    $0x18,%esp         ;...83ec18
  4: mov    $0x95ba54d0,%esi   ;...bed054ba 95
  5: mov    %ecx,0x148(%esi)   ;...898e4801 0000
  <span style="font-weight:bold">6: mfence                    ;...0faef0</span>
  7: mov    %ebp,%esp          ;...8be5
  8: pop    %ebp               ;...5d
		</pre>
<span style="font-weight:bold; color:red"> TODO: Need examples on hardware other than just Intel, but make sure reader knows this is not a comprehensive overview of membars<br/></span>
<span style="font-weight:bold; color:red"> TODO: Get one example of a non bidi fence<br/></span>
<span style="font-weight:bold; color:red"> TODO: The whole article approaches the problem from the perspective of the storing thread<br/></span>			
<span style="font-weight:bold; color:red"> TODO: Make sure readers understands this can and has changed across versions of the JVM</span>			
		<p>
			These instructions were captured on a multi-processing Intel Xeon E5410.
			This short stream of instructions tells a long story.
			The write to the shared volatile variable is on line five.  The JVM must insure
			this write operation appears to happen before all subsequent memory operations performed 
			by the writer thread.
			To honor this guarantee a memory barrier is created with an explicit full fence instruction
			on line six.   
			The mfence instruction is a "full fence" meaning that it forces the processor to 
			serialize both pending read and pending write operations.
		</p>
		<h3>Avoiding costs with Fence Elision</h3>
		<p>
			The JVM is very good at eliminating unnecessary memory barriers.
			Sometimes it gets lucky and the consistency guarantees of the hardware memory model are greater than or equal to those of the Java memory model.  
			When this happens the JVM simply inserts a no op instead of an actual memory barrier.  For example, the memory consistency guarantees of an 
			x86 are strong enough to eliminate the need for a memory barrier when reading a volatile variable.
			The generated assembly instructions for the static get method of the WriterReader class demonstrate this.
		</p>
		<div class="code">
			$ java -XX:+UnlockDiagnosticVMOptions -XX:PrintAssemblyOptions=hsdis-print-bytes -XX:CompileCommand=print,WriterReader.get WriterReader
		</div>
<pre>
  1: push   %ebp               ;...55
  2: mov    %esp,%ebp          ;...8bec
  3: sub    $0x18,%esp         ;...83ec18
  4: mov    $0x95ba54d0,%eax   ;...b8d054ba 95
  5: mov    0x148(%eax),%eax   ;...8b804801 0000
  
  <span style="font-weight:bold">No Fence</span>
  
  6: mov    %ebp,%esp          ;...8be5
  7: pop    %ebp               ;...5d
</pre>	
		<p>
			The volatile read operation on line five is <i>not</i> paired with an explicit fence.  In other words there is no performance penalty for a volatile 
			read instruction on an x86.
		</p>
		<p>
			On a uni-processor system the JVM can insert a no op for <i>all</i> memory barriers because memory operations are already serialized.  
			The following instructions were captured from a runtime compilation of the set method of the WriterReader class using a VMWare workstation 
			image in uni-processor mode.
  		</p>
<pre>
  1: push   %ebp               ;...55
  2: mov    %esp,%ebp          ;...8bec
  3: sub    $0x18,%esp         ;...83ec18
  4: mov    $0x95ba54d0,%esi   ;...bed054ba 95
  5: mov    %ecx,0x148(%esi)   ;...898e4801 0000
  
  <span style="font-weight:bold">No Fence</span>
  
  6: mov    %ebp,%esp          ;...8be5
  7: pop    %ebp               ;...5d		
</pre> 		
		<p>
		Here we observe a volatile write on line five but the JVM does not chase it with a fence.
		</p>	
		<h3>Other ways to Serialize Memory Operations</h3>
		<p>
			Explicit fence instructions are not the only way to serialize memory operations. 
			Let's switch gears with the Counter class to see an example.  
		</p>
		<pre>
	class Counter{
	
	  static int counter = 0;
	
	  public static void main(String[] _){
	       for(int i = 0; i < 100000; i++)
	          inc();
	  }
	
	  static synchronized void inc(){ counter += 1; }
	
	}		
		</pre>
		<p>
			The Counter class performs a classic read-modify-write operation.  The static counter field is not 
			volatile because all three operations must be observed atomically.  For this reason the inc method
			of the Counter class is synchronized.
		</p>
		<p>
			We can compile the Counter class and observe the generated assembly instructions for the synchronized inc method with the following 
			command lines. The Java memory model guarantees the same visibility semantics for exiting of synchronized regions as it does for
			volatile memory operations, so we should expect to see another memory barrier.
		</p>
		<div class="code">
		$ java -XX:+UnlockDiagnosticVMOptions -XX:PrintAssemblyOptions=hsdis-print-bytes -XX:-UseBiasedLocking -XX:CompileCommand=print,Counter.inc Counter
		</div>
		<pre>
   1: push   %ebp               ;...55
   2: mov    %esp,%ebp          ;...8bec
   3: sub    $0x28,%esp         ;...83ec28
   4: mov    $0x95ba5408,%esi   ;...be0854ba 95
   5: lea    0x10(%esp),%edi    ;...8d7c2410
   6: mov    %esi,0x4(%edi)     ;...897704
   7: mov    (%esi),%eax        ;...8b06
   8: or     $0x1,%eax          ;...83c801
   9: mov    %eax,(%edi)        ;...8907
  <span style="font-weight:bold">10: lock cmpxchg %edi,(%esi)  ;...f00fb13e</span>
  11: je     0x011f2dda         ;...0f841000 0000
  12: sub    %esp,%eax          ;...2bc4
  13: and    $0xfffff003,%eax   ;...81e003f0 ffff
  14: mov    %eax,(%edi)        ;...8907
  15: jne    0x011f2e11         ;...0f853700 0000
  16: mov    $0x95ba52b8,%eax   ;...b8b852ba 95
  17: mov    0x148(%eax),%esi   ;...8bb04801 0000
  <span style="font-weight:bold">18: inc    %esi               ;...46</span>
  19: mov    %esi,0x148(%eax)   ;...89b04801 0000
  20: lea    0x10(%esp),%eax    ;...8d442410
  21: mov    (%eax),%esi        ;...8b30
  22: test   %esi,%esi          ;...85f6
  23: je     0x011f2e07         ;...0f840d00 0000
  24: mov    0x4(%eax),%edi     ;...8b7804
  <span style="font-weight:bold">25: lock cmpxchg %esi,(%edi)  ;...f00fb137</span>
  26: jne    0x011f2e1f         ;...0f851800 0000
  27: mov    %ebp,%esp          ;...8be5
  28: pop    %ebp               ;...5d
		</pre>
		<p>
		  To no surprise the number of instructions generated by synchronized is more than volatile.  The increment is found on line 18 but 
		  at no point does the JVM send an explicit fence.  Instead, the JVM has killed two birds with one stone by applying a lock prefix to both cmpxchg instructions
		  on lines 10 and 25.  The symantics of cmpxchg are beyond the scope of this article.  Only the lock prefix is relevant. 
		  The lock prefix not only makes the write operation atomic, it also serializes all pending load and store operations.  
		  The write operation will now become visible before all subsequent memory operations in the program order.
		  If we refactor and run the Counter class to use java.util.concurrent.atomic.AtomicInteger we can observe this same trick.
		</p>
<pre>
	import java.util.concurrent.atomic.AtomicInteger;
	
	class Counter{
	
	  static AtomicInteger counter = new AtomicInteger(0);
	
	  public static void main(String[] args){
	    for(int i = 0; i < 1000000; i++)
	      counter.incrementAndGet(); 
	  }
	
	}
</pre>		
		<div class="code">
		$ java -XX:+UnlockDiagnosticVMOptions -XX:PrintAssemblyOptions=hsdis-print-bytes -XX:CompileCommand=print,*AtomicInteger.incrementAndGet Counter
		</div>
<pre>
   1: push   %ebp               ;...55
   2: mov    %esp,%ebp          ;...8bec
   3: sub    $0x38,%esp         ;...83ec38
   4: jmp    0x043cb20a         ;...e9080000 00
   5: xchg   %ax,%ax            ;...6690<span style="font-weight:bold; color:red"> TODO: this is an implicit lock prefix ... does the JVM 'xchg x x' to serialize here as well?</span>
   6: test   %eax,0xb788d100    ;...850500d1 88b7
   7: mov    0x8(%ecx),%eax     ;...8b4108
   8: mov    %eax,%esi          ;...8bf0
   9: inc    %esi               ;...46
  10: mov    $0x9a3f03d0,%edi   ;...bfd0033f 9a
  11: mov    0x160(%edi),%edi   ;...8bbf6001 0000
  12: mov    %ecx,%edi          ;...8bf9
  13: add    $0x8,%edi          ;...83c708
  <span style="font-weight:bold">14: lock cmpxchg %esi,(%edi)  ;...f00fb137</span>
  15: mov    $0x1,%eax          ;...b8010000 00
  16: je     0x043cb234         ;...0f840500 0000
  17: mov    $0x0,%eax          ;...b8000000 00
  18: cmp    $0x0,%eax          ;...83f800
  19: je     0x043cb204         ;...74cb
  20: mov    %esi,%eax          ;...8bc6
  21: mov    %ebp,%esp          ;...8be5
  22: pop    %ebp               ;...5d
</pre>		
		<p>
			Again we see the write operation being combined with a lock prefix on line 14.  This insures the new 
			value of the variable will become visible to other threads before all subsequent memory operations.
		</p>
		<h3>Reference Materials</h3>
		<p>
		
		</p>
		<h3>About the Author </h3>
		<p>
			<a href="http://notdennisbyrne.blogspot.com/">Dennis Byrne</a> is a senior software engineer for
			<a href="http://drwholdings.com/">DRW Trading</a>, a proprietary trading firm and liquidity provider.  
			He is a writer, presenter and active member of the open source community.
		</p>
		<br/>
		<br/>
		<br/>
		<br/>
		<br/>
		<br/>
		<br/>
		<br/>
		<br/>
		<br/>
		<br/>
		<br/>		
		<br/>
		
<br/>
<br/>
<br/>
<br/>
<br/>
<br/>
<br/>
<br/>
<br/>
	</body>
</html>