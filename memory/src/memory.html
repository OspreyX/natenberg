<html>
	<head>
		<style>
			.code{
				background-color: #CCCCCC;
				padding: 10px
			}
		</style>
	</head>
	<body>
		<p>
			This article is about ...
		</p>
		<p>
			Let's begin with a simple Java class.
		</p>
		<pre>
	class Volatile{
	
	  public static volatile int v = 0;
	
	  public static void main(String[] _){
	       for(int i = 0; i < 100000; i++)
	          inc();
	  }
	
	  private static void inc(){ v += 1; }
	
	}		
		</pre>
		<p>
			This class increments a volatile primitive integer.  Hopefully the reader knows volatile variables are not safe to 
			use as counters.  If not, you are about to find out why as we dive into the assembly instructions this program produces.
			To obtain the assembly language instructions for this program we have to first install a special
			debug version of the JVM.  The following will work for Linux.  Sun 
			<a target="new" href="http://download.java.net/jdk6/binaries/">has installers</a> for Solaris or Windows
			as well.
		</p>
		<div class="code">
			$ wget http://www.java.net/download/jdk6/6u18/promoted/b05/binaries/jdk-6u18-ea-bin-b05-linux-i586-debug-18_nov_2009.jar<br/>
			$ mv "jdk-6u18-ea-bin-b05-linux-i586-debug-18_nov_2009.jar?e=1258770582&h=67548292b3c14c86f56d40f66b94c302" jdk-6u18-ea-bin-b05-linux-i586-debug-18_nov_2009.jar<br/>
			$ java -jar jdk-6u18-ea-bin-b05-linux-i586-debug-18_nov_2009.jar<br/>
		</div>
		<p>
			Next we have to install a disassembler. The Kenai project <a href="http://kenai.com/projects/base-hsdis/downloads" target="new">has binaries</a>
			for Solaris, Linux and BSD.  If you are on Windows, you can build 
			<a href="http://hg.openjdk.java.net/jdk7/hotspot/hotspot/file/tip/src/share/tools/hsdis/" target="new">hsdis</a> from source.
		</p>
		<div class="code">
			$ wget http://kenai.com/projects/base-hsdis/downloads/download/linux-hsdis-i386.so<br/>
			$ cp linux-hsdis-i386.so /usr/lib/jvm/java-6-openjdk/jre/lib/i386/server/<br/>
			$ cp linux-hsdis-i386.so /usr/lib/jvm/java-6-openjdk/jre/lib/i386/client/<br/>
			$ cp linux-hsdis-i386.so /usr/lib/jvm/java-6-openjdk/jre/lib/i386/cacao/<br/>
		</div>
		<p>
			Now we are ready to compile and run this program, capturing the assembly instructions produced by the JIT compiler.
		</p>
		<div class="code">		
			$ /usr/lib/jvm/java-6-openjdk/bin/javac Volatile.java<br/>
			$ /usr/lib/jvm/java-6-openjdk/jre/bin/java -XX:+UnlockDiagnosticVMOptions -XX:PrintAssemblyOptions=hsdis-print-bytes -Xbatch -XX:CompileCommand=print,Volatile.inc Volatile
		</div>
		<p>
			The relevant output of this program falls between the push and pop instructions.  Keep in mind that we are now beyond the platform 
			independent source code of Java.  These instructions are specific to the hardware the program was run on, a symmetric multiprocessing
			 Intel Xeon CPU E5410.  We can observe many things about the Java memory model from this small stream of instructions.
		</p>
		<pre>
   1: push   %ebp               
   2: mov    %esp,%ebp          
   3: sub    $0x18,%esp         
   4: mov    $0x95ba52b8,%esi   
   5: mov    0x148(%esi),%edi   
   6: inc    %edi               
   7: mov    %edi,0x148(%esi)   
   8: mfence                    
   9: mov    %ebp,%esp          
  10: pop    %ebp               		
		</pre>
		<p>
			The read of this programs static volatile variable is on line (TODO).  The write to this static volatile variable is on line (TODO).
			There is nothing to prevent a to threads from loading this value before either of them have written to it.  When this happens, the 
			store operation of the second thread will clobber the increment of the first thread to perform the inc instruction on line six.
		</p>
		<p>
			The most important instruction is on line eight, the mfence instruction.  The mfence instruction tells the processor that we wish 
			to create a memory barrier.  To explain this barrier we must first cover a few things about the underlying hardware.  
			Nowadays, memory latency is a major bottleneck.  A trip to main memory can cost in the neighborhood of 200 to 300 clock cycles (TODO).
			One of the ways hardware manufacturers hide this latency is to use a cache hierarchy.  These caches are write-behind caches, rather 
			than write through.  This means that when a program write to a variable, the cache does not have to write the value all the way 
			through to main memory.  Instead, the processor can "promise" to perform this operation at a later time using a write buffer.  
			The write operations of the buffer are often referred to as "queuing up".  However is more accurate to think of these operations as
			"accumulating", rather than "queuing up" because the operations can be performed in an order other than the order they were given by 
			the program.
		</p>
		<p>
			The mfence instruction tells the processor that it must flush both the write and read buffers before it can proceed.  
		</p>
		<p>
			Notice how there is no fence associated with the read of this static volatile variable?
		</p>
		<br/>
		<br/>
		<br/>
		volatile does not go out to main memory
		volatile does not incur a read cost on x86
		you cannot expire a cache
		<br/>
		<br/>
	</body>
</html>