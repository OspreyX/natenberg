<html>
	<head>
		<title>Memory Barriers and the JVM</title>
		<style>
			.code{
				background-color: #CCCCCC;
				padding: 10px
			}
		</style>
	</head>
	<body>
		<h1>Memory Barriers and the JVM</h1>
		<p>
			Memory barriers are a set of processor instructions used to apply ordering limitations on memory operations.  		
			This article covers the impact memory barriers have on the performance and determinism of any multi-threaded program.
			We'll look at how the JVM uses memory barriers to implement volatile, synchronized and atomic conditionals.
			This is not an article about mutual exclusion, parallelism or atomic operations per se.
			Memory barriers are used to achieve an equally important element of concurrent programming called visibility.
		</p>
		<h3>Memory Barriers Are Expensive</h3>
		<p>
			The costs of memory latency have pushed processors to reorder and cache memory operations.
			A trip to main memory costs hundreds of clock cycles on commodity hardware.
			Processors use caching to decrease latency costs of memory operations by orders of magnitude.  
			These caches are write-back, not write-through.
			This means the value of a write operation does not immediately have to be written all the way out to main memory.
			The processor instead places this operation in a buffer and is now obligated to perform this operation at a later time.
			Buffered operations are said to be "in flight".
			Buffers are often misunderstood as queues. They are not.  
			In-flight operations are not necessarily performed in the order in which they are fed to the processor.
			This is good when data is confined to the scope of one thread because it opens the door for many optimizations.  
		</p>
		<p>
			Combining these optimizations with symmetric multi-processing and shared mutable state is a nightmare.
			Programs can behave non-deterministically when memory operations on shared mutable state are re-ordered.  
			It is possible for a thread to write values that become visible to another thread in an order that is inconsistent 
			with the order in which they were written.
			A good program prevents this problem using memory barriers at the right times.
			Memory barriers are expensive - they instruct a processor to serialize pending memory operations.
		</p>
		<h3>Memory Barriers As Protocols</h3>
		<p>
			The JVM translates language level concurrency primitives into memory barriers. 
			Let's look at the source code and assembly instructions of some simple Java programs to see how. 
			This requires the latest OpenJDK release or a new version of HotSpot, update 14 or above.
			A disassembler plugin is also required. The Kenai project <a href="http://kenai.com/projects/base-hsdis/downloads" target="new">has binaries</a>
			for Solaris, Linux and BSD.  The <a href="http://hg.openjdk.java.net/jdk7/hotspot/hotspot/file/tip/src/share/tools/hsdis/" target="new">hsdis</a>
			plugin is an alternative that can be built from source for Windows.  The following works for Linux.
		</p>
		<div class="code">
			$ wget http://kenai.com/projects/base-hsdis/downloads/download/linux-hsdis-i386.so<br/>
			$ cp linux-hsdis-i386.so /usr/lib/jvm/java-6-openjdk/jre/lib/i386/server/<br/>
			$ cp linux-hsdis-i386.so /usr/lib/jvm/java-6-openjdk/jre/lib/i386/client/<br/>
		</div>
		<p>
			Let's begin a crash course in memory barriers with the WriterReader class.
			There are seemingly pointless for loops in the source code for all of our examples.  
			Ignore these.  These are only used to trigger JIT compilation.
		</p>
		<pre>
	class WriterReader{
	
	  static volatile int a = 0;
	  static volatile int b = 0;
	
	  public static void main(String[] _){
	    Thread reader = new Thread(){
	      public void run(){
	        for(int i = 0; i < 10000; i++)
	          read();
	      }
	    };	  
	    Thread writer = new Thread(){
	      public void run(){
	        for(int i = 0; i < 10000; i++)
	          write(i);
	      }
	    };
	    reader.start(); 
	    writer.start();
	  }

	  static void read(){
	    int aLocal = a;
	    int bLocal = b;
	  }
	
	  static void write(int newValue){ 
	    a = newValue;
	    b = newValue;
	  }
	
	}
</pre>
		<p>
			The main method of this class creates two threads.  The writer thread writes to two static volatile variables.
			The reader thread reads these variables.  
			Consider the point of view of the reader thread.
			The reader thread should expect to observe a to be equal to b, or a to be greater than b, but it 
			should never expect to observe b to be greater than a.  
			Without the volatile modifier the reader could in fact observe b to be greater than a.  
			That is, the reader thread could observe the write to b before the write to a. 
			Using the keyword volatile prevents this problem because it established a <i>happens before</i> relationship between the write to a and the write to b.
			A peek under the hood shows why.
			This command allows us to capture the assembly instructions for the WriterReader.
			The CompileCommand option is used to filter these instructions down to just those for the static TODO method.
		</p>
		<div class="code">
			$ java -XX:+UnlockDiagnosticVMOptions -XX:PrintAssemblyOptions=hsdis-print-bytes -XX:CompileCommand=print,WriterReader.set WriterReader
		</div>
		<p>
			The set method translates to the instructions found between push and pop.
			These instructions were captured on a multi-processing Intel Xeon E5410.
		</p>
		<pre>
  1: push   %ebp               ;...55
  2: mov    %esp,%ebp          ;...8bec
  3: sub    $0x18,%esp         ;...83ec18
  4: mov    $0x95ba54d0,%esi   ;...bed054ba 95
  5: mov    %ecx,0x148(%esi)   ;...898e4801 0000
  <span style="font-weight:bold">6: mfence                    ;...0faef0</span>
  7: mov    %ebp,%esp          ;...8be5
  8: pop    %ebp               ;...5d
		</pre>
<span style="font-weight:bold; color:red"> TODO: Get one example of a non bidi fence<br/></span>
<span style="font-weight:bold; color:red"> TODO: The whole article approaches the problem from the perspective of the storing thread<br/></span>			
<span style="font-weight:bold; color:red"> TODO: Make sure readers understands this can and has changed across versions of the JVM</span>			
		<p>
			This short stream of instructions tells a long story.
			The write to the shared volatile variable is on line five.  The JVM must insure
			this write operation appears to happen before all subsequent memory operations performed 
			by the writer thread.
			To honor this guarantee a memory barrier is created with an explicit fence instruction
			on line six.   
			The mfence instruction is a "full fence", or bidirectional fence.  A full fence forces the processor to 
			serialize both pending read and pending write operations.
		</p>
		<h3>Memory Barriers Are Hardware Specific</h3>
		<p><span style="font-weight:bold; color:red">TODO ... replace the above with PowerPC example ... move x86 example to here. make sure reader knows this is not a comprehensive overview of membars</span></p>
		<h3>Memory Barriers Do Not Have To Be Explicit</h3>
		<p>
			Explicit fence instructions are not the only way to serialize memory operations. 
			Let's switch gears with the Counter class to see an example.  
		</p>
		<pre>
	class Counter{
	
	  static int counter = 0;
	
	  public static void main(String[] _){
	       for(int i = 0; i < 100000; i++)
	          inc();
	  }
	
	  static synchronized void inc(){ counter += 1; }
	
	}		
		</pre>
		<p>
			The Counter class performs a classic read-modify-write operation.  The static counter field is not 
			volatile because all three operations must be observed atomically.  For this reason the inc method
			of the Counter class is synchronized.
		</p>
		<p>
			We can compile the Counter class and observe the generated assembly instructions for the synchronized inc method with the following 
			command lines. The Java memory model guarantees the same visibility semantics for exiting of synchronized regions as it does for
			volatile memory operations, so we should expect to see another memory barrier.
		</p>
		<div class="code">
		$ java -XX:+UnlockDiagnosticVMOptions -XX:PrintAssemblyOptions=hsdis-print-bytes -XX:-UseBiasedLocking -XX:CompileCommand=print,Counter.inc Counter
		</div>
		<pre>
   1: push   %ebp               ;...55
   2: mov    %esp,%ebp          ;...8bec
   3: sub    $0x28,%esp         ;...83ec28
   4: mov    $0x95ba5408,%esi   ;...be0854ba 95
   5: lea    0x10(%esp),%edi    ;...8d7c2410
   6: mov    %esi,0x4(%edi)     ;...897704
   7: mov    (%esi),%eax        ;...8b06
   8: or     $0x1,%eax          ;...83c801
   9: mov    %eax,(%edi)        ;...8907
  <span style="font-weight:bold">10: lock cmpxchg %edi,(%esi)  ;...f00fb13e</span>
  11: je     0x011f2dda         ;...0f841000 0000
  12: sub    %esp,%eax          ;...2bc4
  13: and    $0xfffff003,%eax   ;...81e003f0 ffff
  14: mov    %eax,(%edi)        ;...8907
  15: jne    0x011f2e11         ;...0f853700 0000
  16: mov    $0x95ba52b8,%eax   ;...b8b852ba 95
  17: mov    0x148(%eax),%esi   ;...8bb04801 0000
  <span style="font-weight:bold">18: inc    %esi               ;...46</span>
  19: mov    %esi,0x148(%eax)   ;...89b04801 0000
  20: lea    0x10(%esp),%eax    ;...8d442410
  21: mov    (%eax),%esi        ;...8b30
  22: test   %esi,%esi          ;...85f6
  23: je     0x011f2e07         ;...0f840d00 0000
  24: mov    0x4(%eax),%edi     ;...8b7804
  <span style="font-weight:bold">25: lock cmpxchg %esi,(%edi)  ;...f00fb137</span>
  26: jne    0x011f2e1f         ;...0f851800 0000
  27: mov    %ebp,%esp          ;...8be5
  28: pop    %ebp               ;...5d
		</pre>
		<p>
		  To no surprise the number of instructions generated by synchronized is more than volatile.  The increment is found on line 18 but 
		  at no point does the JVM send an explicit fence.  Instead, the JVM has killed two birds with one stone using a lock prefixed cmpxchg instruction 
		  on lines 10 and 25.  The symantics of cmpxchg are beyond the scope of this article.  
		  What's relevant is that 'lock cmpxchg' not only performs the write operation atomically but that all pending load and store operations are serialized.  
		  The write operation will now become visible before all subsequent memory operations in the program order.
		  If we refactor and run the Counter class to use java.util.concurrent.atomic.AtomicInteger we can observe this same trick.
		</p>
<pre>
	import java.util.concurrent.atomic.AtomicInteger;
	
	class Counter{
	
	  static AtomicInteger counter = new AtomicInteger(0);
	
	  public static void main(String[] args){
	    for(int i = 0; i < 1000000; i++)
	      counter.incrementAndGet(); 
	  }
	
	}
</pre>		
		<div class="code">
		$ java -XX:+UnlockDiagnosticVMOptions -XX:PrintAssemblyOptions=hsdis-print-bytes -XX:CompileCommand=print,*AtomicInteger.incrementAndGet Counter
		</div>
<pre>
   1: push   %ebp               ;...55
   2: mov    %esp,%ebp          ;...8bec
   3: sub    $0x38,%esp         ;...83ec38
   4: jmp    0x043cb20a         ;...e9080000 00
   5: xchg   %ax,%ax            ;...6690<span style="font-weight:bold; color:red"> TODO: this is an implicit lock prefix ... does 'xchg x x' serialize or is this a NOP?</span>
   6: test   %eax,0xb788d100    ;...850500d1 88b7
   7: mov    0x8(%ecx),%eax     ;...8b4108
   8: mov    %eax,%esi          ;...8bf0
   9: inc    %esi               ;...46
  10: mov    $0x9a3f03d0,%edi   ;...bfd0033f 9a
  11: mov    0x160(%edi),%edi   ;...8bbf6001 0000
  12: mov    %ecx,%edi          ;...8bf9
  13: add    $0x8,%edi          ;...83c708
  <span style="font-weight:bold">14: lock cmpxchg %esi,(%edi)  ;...f00fb137</span>
  15: mov    $0x1,%eax          ;...b8010000 00
  16: je     0x043cb234         ;...0f840500 0000
  17: mov    $0x0,%eax          ;...b8000000 00
  18: cmp    $0x0,%eax          ;...83f800
  19: je     0x043cb204         ;...74cb
  20: mov    %esi,%eax          ;...8bc6
  21: mov    %ebp,%esp          ;...8be5
  22: pop    %ebp               ;...5d
</pre>		
		<p>
			Again we see the write operation being combined with a lock prefix on line 14.  This insures the new 
			value of the variable will become visible to other threads before all subsequent memory operations.
		</p>		
		<h3>Memory Barriers Can Be Avoided</h3>
		<p>
			The JVM is very good at eliminating unnecessary memory barriers.
			Sometimes it gets lucky and the consistency guarantees of the hardware memory model are greater than or equal to those of the Java memory model.  
			When this happens the JVM simply inserts a no op instead of an actual memory barrier.  For example, the memory consistency guarantees of an 
			x86 are strong enough to eliminate the need for a memory barrier when reading a volatile variable.
			The generated assembly instructions for the static get method of the WriterReader class demonstrate this.
		</p>
		<div class="code">
			$ java -XX:+UnlockDiagnosticVMOptions -XX:PrintAssemblyOptions=hsdis-print-bytes -XX:CompileCommand=print,WriterReader.get WriterReader
		</div>
<pre>
  1: push   %ebp               ;...55
  2: mov    %esp,%ebp          ;...8bec
  3: sub    $0x18,%esp         ;...83ec18
  4: mov    $0x95ba54d0,%eax   ;...b8d054ba 95
  5: mov    0x148(%eax),%eax   ;...8b804801 0000
  
  <span style="font-weight:bold">No Fence</span>
  
  6: mov    %ebp,%esp          ;...8be5
  7: pop    %ebp               ;...5d
</pre>	
		<p>
			The volatile read operation on line five is <i>not</i> paired with an explicit fence.  In other words there is no performance penalty for a volatile 
			read instruction on an x86.
		</p>
		<p>
			On a uni-processor system the JVM can insert a no op for <i>all</i> memory barriers because memory operations are already serialized.  
			The following instructions were captured from a runtime compilation of the set method of the WriterReader class using a VMWare workstation 
			image in uni-processor mode.
  		</p>
<pre>
  1: push   %ebp               ;...55
  2: mov    %esp,%ebp          ;...8bec
  3: sub    $0x18,%esp         ;...83ec18
  4: mov    $0x95ba54d0,%esi   ;...bed054ba 95
  5: mov    %ecx,0x148(%esi)   ;...898e4801 0000
  
  <span style="font-weight:bold">No Fence</span>
  
  6: mov    %ebp,%esp          ;...8be5
  7: pop    %ebp               ;...5d		
</pre> 		
		<p>
		Here we observe a volatile write on line five but the JVM does not chase it with a fence.
		</p>	
		<h3>Reference Materials</h3>
		<p>
		
		</p>
		<h3>About the Author </h3>
		<p>
			<a href="http://notdennisbyrne.blogspot.com/">Dennis Byrne</a> is a senior software engineer for
			<a href="http://drwholdings.com/">DRW Trading</a>, a proprietary trading firm and liquidity provider.  
			He is a writer, presenter and active member of the open source community.
		</p>
		<br/>
		<br/>
		<br/>
		<br/>
		<br/>
		<br/>
		<br/>
		<br/>
		<br/>
		<br/>
		<br/>
		<br/>		
		<br/>
		
<br/>
<br/>
<br/>
<br/>
<br/>
<br/>
<br/>
<br/>
<br/>
	</body>
</html>