<html>
	<head>
		<title>Memory Barriers and the JVM</title>
		<style>
			.code{
				background-color: #CCCCCC;
				padding: 10px
			}
		</style>
	</head>
	<body>
		<h1>Memory Barriers and the JVM</h1>
		<p>
			Memory barriers, or fences, are a set of processor instructions used to apply ordering limitations on memory operations.  		
			This article explains the impact memory barriers have on the determinism of multi-threaded programs.
			We'll look at how memory barriers relate to JVM concurrency constructs such as volatile, synchronized and atomic conditionals. 
			It is assumed the reader has a solid understanding of these concepts and the Java memory model as a whole.
			This is not an article about mutual exclusion, parallelism or atomicity per se.
			Memory barriers are used to achieve an equally important element of concurrent programming called visibility.
		</p>
		<h3>What Are Memory Barriers?</h3>
		<p>
			The costs of memory latency have pushed processors to reorder and cache memory operations.
			A trip to main memory costs hundreds of clock cycles on commodity hardware.
			Processors use caching to decrease latency costs of memory operations by orders of magnitude.
			These caches introduce a substantial visibility delay because the value of each write operation does not immediately "write through" to main memory.
			The processor instead places this operation in a buffer and is obligated to "write back" the value later.
			Buffers are often misunderstood as queues. They are not.
			Pending memory operations are not necessarily performed in the order in which they are fed to the processor.
			This opens the door for many optimizations when data is confined to the scope of one thread, or when data is immutable and used by many threads.  
		</p>
		<p>
			Combining these optimizations with symmetric multi-processing and shared mutable state is a nightmare.
			A program can behave non-deterministically when memory operations on shared mutable state are re-ordered.  
			It is possible for a thread to write values that become visible to another thread in an order that is inconsistent 
			with the order in which they were written.
			A well placed memory barrier prevents this problem by forcing the processor to serialize pending memory operations.
			The performance implications of memory barriers are beyond the scope of this article.
		</p>
		<h3>Memory Barriers As Protocols</h3>
		<p>
			Memory barriers are not directly exposed by the JVM; 
			instead they are inserted into the instruction sequence by the JVM in order to uphold the semantics of language level concurrency primitives.
			Let's look at the source code and assembly instructions of some simple Java programs to see how. 
			This requires the latest OpenJDK release or a new version of HotSpot, update 14 or above.
			A disassembler plugin is also required. The Kenai project <a href="http://kenai.com/projects/base-hsdis/downloads" target="new">has binaries</a>
			for Solaris, Linux and BSD.  The <a href="http://hg.openjdk.java.net/jdk7/hotspot/hotspot/file/tip/src/share/tools/hsdis/" target="new">hsdis</a>
			plugin is an alternative that can be built from source for Windows.  The following works for Linux.
		</p>
		<div class="code">
			$ wget http://kenai.com/projects/base-hsdis/downloads/download/linux-hsdis-i386.so<br/>
			$ cp linux-hsdis-i386.so /usr/lib/jvm/java-6-openjdk/jre/lib/i386/server/<br/>
			$ cp linux-hsdis-i386.so /usr/lib/jvm/java-6-openjdk/jre/lib/i386/client/<br/>
		</div>
		<p>
			Let's begin a crash course in memory barriers with the WriterReader class.
			The for loops in this source code should be ignored.
			These are only used to trigger JIT compilation.
		</p>
		<pre>
   class WriterReader{
	
      static volatile int shared = 0;
      static volatile boolean ready = false;
	
      public static void main(String[] _){
         Thread reader = new Thread(){
            public void run(){
               for(int i = 0; i < 10000; i++)
                  read();
            }
         };
         reader.start();
	    
         Thread writer = new Thread(){
            public void run(){
               for(int i = 0; i < 10000; i++)
                  write();
            }
         };
         writer.start();
      }

      static int read(){
         return ready ? shared : -1;
      }
	
      static void write(){
         shared = 42;
         ready = true;
      }

   }
</pre>
		<p>
			The main method of this class creates two threads.  
			The writer thread writes to the shared static volatile variable and then writes to the ready static volatile variable.
			The reader thread reads the ready variable and then conditionally reads the shared variable.  
			Consider the point of view of the reader thread.
			The reader thread should expect the read method to return -1 when ready is false and 42 when ready is true. 
			The reader thread should never expect the read method to return zero, the original value of the shared variable.
			Without the volatile modifier the reader could in fact observe zero for the value of shared.
			That is, without the volatile modifier the reader thread could observe the write to ready before the write to shared. 
			Using the keyword volatile prevents this problem because it establishes a <i>happens before</i> relationship between the write to ready and the write to shared.
			The compiler cannot re-order these write operations and if necessary it must forbid the processor from doing so.
			A peek under the hood shows how.
			The following command allows us to capture the assembly instructions for the WriterReader.
			The CompileCommand option is used to filter these instructions down to just those for the static read method.
		</p>
		<div class="code">
			$ java -XX:+UnlockDiagnosticVMOptions -XX:PrintAssemblyOptions=hsdis-print-bytes -XX:CompileCommand=print,WriterReader.read WriterReader
		</div>
		<p>
			The read method translates to the instructions found between push and pop.
			These instructions were captured on a multi-processing <span style="font-weight:bold; color:red"> TODO: get a hold of a itanium, or figure out how to build open jdk on powerpc</span>.
		</p>
<pre>
<span style="font-weight:bold; color:red">     TODO non x86/SPARC assembly instructions for read/0 here.</span>
</pre>	
		<p>
			This short stream of instructions tells a long story.
			The reads of both volatile variables are on lines <span style="font-weight:bold; color:red">N</span> and <span style="font-weight:bold; color:red">N + M</span>.  
			The Java memory model guarantees the JVM will deliver these instructions to the processor in program order - 
			but this alone would not be enough because the processor is still free to perform these operations out of order.
			To uphold the consistency guarantees of the Java memory model the JVM creates a memory barrier via an explicit <span style="font-weight:bold; color:red">TODO: instruction name</span> instruction on line <span style="font-weight:bold; color:red">N+1</span>.
			<span style="font-weight:bold; color:red">TODO: info on the instruction itself.</span>
			A memory barrier that enforces ordering limitations on reads <i>or</i> writes is said to be unidirectional.
			A memory barrier that enforces ordering limitations on reads <i>and</i> writes is said to be bidirectional, or, a full fence.  
			The <span style="font-weight:bold; color:red">TODO unidirectional membar instruction</span> is a unidirectional memory barrier.
		</p>
		<p>
			Consistency is a two way street.
			How useful is it for the reader thread to insert a memory barrier between both reads if the writer thread does not separate both writes with one as well?
			In order for threads to communicate they must <i>all</i> obey the protocol; just like nodes on a network, or people on a team.
			If one thread breaks formation than the efforts of all other threads are rendered useless.
			We should expect to see memory barriers in the assembly instructions for the write method of the WriterReader.
		</p>
		<div class="code">
			$ java -XX:+UnlockDiagnosticVMOptions -XX:PrintAssemblyOptions=hsdis-print-bytes -XX:CompileCommand=print,WriterReader.write WriterReader
		</div>	
<pre>
<span style="font-weight:bold; color:red">     TODO non x86/SPARC assembly instructions for write/0 here.</span>
</pre>
		<p>
			Here we can see both write operations are chased with explicit memory barriers on lines <span style="font-weight:bold; color:red">X</span>
			and <span style="font-weight:bold; color:red">Y</span>.
			<span style="font-weight:bold; color:red">TODO: info on the instruction itself.</span>
			This completes both sides of the protocol because each write operation <i>happens before</i> subsequent memory operations.
		</p>		
		<h3>Memory Barriers Are Hardware Specific</h3>
		<p>
			This article does not aim to be a comprehensive overview of all memory barriers.
			This would be a monumental task.
			But it is important though to appreciate the fact that these instructions vary considerably across different hardware architectures.
			Below is what the write method of WriterReader translates to on a multi-processing Intel Xeon E5410 and a SPARC workstation.
			All remaining assembly instruction sequences in this article were captured on an Intel Xeon unless specified otherwise.
		</p>
<table>
<tr>
<td>
The WriterReader.write method on x86.
</td>
<td>
The WriterReader.write method on SPARC.
</td>
</tr>
<tr>
<td valign="top">
<pre>

  0x00f78017: push   %ebp               ;...55
  0x00f78018: mov    %esp,%ebp          ;...8bec
  0x00f7801a: sub    $0x18,%esp         ;...83ec18
  0x00f7801d: mov    $0x95ba53c0,%esi   ;...bec053ba 95
  0x00f78022: mov    $0x2a,%edi         ;...bf2a0000 00
  0x00f78027: mov    %edi,0x148(%esi)   ;...89be4801 0000
  <span style="font-weight:bold">0x00f7802d: mfence                    ;...0faef0</span>
  0x00f78030: mov    $0x1,%edi          ;...bf010000 00
  0x00f78035: mov    %edi,%ebx          ;...8bdf
  0x00f78037: mov    %bl,0x14c(%esi)    ;...889e4c01 0000
  0x00f7803d: mfence                    ;...0faef0
  0x00f78040: mov    %ebp,%esp          ;...8be5
  0x00f78042: pop    %ebp               ;...5d
</pre>
</td>
<td>
<pre>

  0xfa8ecea0: save  %sp, -72, %sp       ;...9de3bfb8
  0xfa8ecea4: sethi  %hi(0xb61f9000), %l1  ;...232d87e4
  0xfa8ecea8: add  %l1, 0x3d8, %l1	! 'WriterReader'
  0xfa8eceac: mov  0x2a, %l0            ;...a010202a
  0xfa8eceb0: st  %l0, [ %l1 + 0x150 ]  ;...e0246150
  0xfa8eceb4: mov  1, %l2               ;...a4102001
  0xfa8eceb8: stb  %l2, [ %l1 + 0x154 ]  ;...e42c6154
  <span style="font-weight:bold">0xfa8ecebc: membar  #StoreLoad        ;...8143e002</span>
  0xfa8ecec0: sethi  %hi(0xff3fc000), %l0  ;...213fcff0
  0xfa8ecec4: ld  [ %l0 ], %g0          ;...c0042000
                                        ;   {poll_return}  
  0xfa8ecec8: ret                       ;...81c7e008
  0xfa8ececc: restore                   ;...81e80000
</pre>
</td>
</tr>
</table>
		<p>
			On the x86 the JVM chases both write operations with an mfence instruction, an explicit bidirectional memory barrier.  
			On the SPARC the JVM shows a little more trust with a single membar instruction.
		</p>
		<h3>Memory Barriers Can Be Explicit or Implicit</h3>
		<p>
			Explicit fence instructions are not the only way to serialize memory operations. 
			Let's switch gears to the Counter class to see an example.  
		</p>
		<pre>
    class Counter{
	
        static int counter = 0;
	
        public static void main(String[] _){
            for(int i = 0; i < 100000; i++)
                inc();
        }
	
        static synchronized void inc(){ counter += 1; }
	
    }		
		</pre>
		<p>
			The Counter class performs a classic read-modify-write operation.  
			The static counter field is not volatile because all three operations must be observed atomically.  
			For this reason the inc method of the Counter class is synchronized.
			We can compile the Counter class and observe the generated assembly instructions for the synchronized inc method with the following command. 
			The Java memory model guarantees the same visibility semantics for exiting of synchronized regions as it does for
			volatile memory operations, so we should expect to see another memory barrier.
		</p>
		<div class="code">
		$ java -XX:+UnlockDiagnosticVMOptions -XX:PrintAssemblyOptions=hsdis-print-bytes -XX:-UseBiasedLocking -XX:CompileCommand=print,Counter.inc Counter
		</div>
		<pre>
   1: push   %ebp               ;...55
   2: mov    %esp,%ebp          ;...8bec
   3: sub    $0x28,%esp         ;...83ec28
   4: mov    $0x95ba5408,%esi   ;...be0854ba 95
   5: lea    0x10(%esp),%edi    ;...8d7c2410
   6: mov    %esi,0x4(%edi)     ;...897704
   7: mov    (%esi),%eax        ;...8b06
   8: or     $0x1,%eax          ;...83c801
   9: mov    %eax,(%edi)        ;...8907
  <span style="font-weight:bold">10: lock cmpxchg %edi,(%esi)  ;...f00fb13e</span>
  11: je     0x011f2dda         ;...0f841000 0000
  12: sub    %esp,%eax          ;...2bc4
  13: and    $0xfffff003,%eax   ;...81e003f0 ffff
  14: mov    %eax,(%edi)        ;...8907
  15: jne    0x011f2e11         ;...0f853700 0000
  16: mov    $0x95ba52b8,%eax   ;...b8b852ba 95
  17: mov    0x148(%eax),%esi   ;...8bb04801 0000
  <span style="font-weight:bold">18: inc    %esi               ;...46</span>
  19: mov    %esi,0x148(%eax)   ;...89b04801 0000
  20: lea    0x10(%esp),%eax    ;...8d442410
  21: mov    (%eax),%esi        ;...8b30
  22: test   %esi,%esi          ;...85f6
  23: je     0x011f2e07         ;...0f840d00 0000
  24: mov    0x4(%eax),%edi     ;...8b7804
  <span style="font-weight:bold">25: lock cmpxchg %esi,(%edi)  ;...f00fb137</span>
  26: jne    0x011f2e1f         ;...0f851800 0000
  27: mov    %ebp,%esp          ;...8be5
  28: pop    %ebp               ;...5d
		</pre>
		<p>
		  To no surprise the number of instructions generated by synchronized is more than volatile.  The increment is found on line 18 but 
		  at no point does the JVM insert an explicit memory barrier.  Instead, the JVM has killed two birds with one stone using a lock prefixed cmpxchg instruction 
		  on lines 10 and 25.  The semantics of cmpxchg are beyond the scope of this article.  
		  What's relevant is that 'lock cmpxchg' not only performs the write operation atomically - it also flushes pending read and write operations.  
		  The write operation will now become visible before all subsequent memory operations.
		  If we refactor and run the Counter class to use java.util.concurrent.atomic.AtomicInteger we can observe this same trick.
		</p>
<pre>
    import java.util.concurrent.atomic.AtomicInteger;
	
    class Counter{
	
        static AtomicInteger counter = new AtomicInteger(0);
	
        public static void main(String[] args){
            for(int i = 0; i < 1000000; i++)
                counter.incrementAndGet(); 
        }
	
    }
</pre>		
		<div class="code">
		$ java -XX:+UnlockDiagnosticVMOptions -XX:PrintAssemblyOptions=hsdis-print-bytes -XX:CompileCommand=print,*AtomicInteger.incrementAndGet Counter
		</div>
<pre>
   1: push   %ebp               ;...55
   2: mov    %esp,%ebp          ;...8bec
   3: sub    $0x38,%esp         ;...83ec38
   4: jmp    0x043cb20a         ;...e9080000 00
   5: xchg   %ax,%ax            ;...6690
   6: test   %eax,0xb788d100    ;...850500d1 88b7
   7: mov    0x8(%ecx),%eax     ;...8b4108
   8: mov    %eax,%esi          ;...8bf0
   9: inc    %esi               ;...46
  10: mov    $0x9a3f03d0,%edi   ;...bfd0033f 9a
  11: mov    0x160(%edi),%edi   ;...8bbf6001 0000
  12: mov    %ecx,%edi          ;...8bf9
  13: add    $0x8,%edi          ;...83c708
  <span style="font-weight:bold">14: lock cmpxchg %esi,(%edi)  ;...f00fb137</span>
  15: mov    $0x1,%eax          ;...b8010000 00
  16: je     0x043cb234         ;...0f840500 0000
  17: mov    $0x0,%eax          ;...b8000000 00
  18: cmp    $0x0,%eax          ;...83f800
  19: je     0x043cb204         ;...74cb
  20: mov    %esi,%eax          ;...8bc6
  21: mov    %ebp,%esp          ;...8be5
  22: pop    %ebp               ;...5d
</pre>		
		<p>
			Again we see the write operation being combined with a lock prefix on line 14.  This insures the new 
			value of the variable will become visible to other threads before all subsequent memory operations.
		</p>		
		<h3>Memory Barriers Can Be Avoided</h3>
		<p>
			The JVM is very good at eliminating unnecessary memory barriers.
			Often it gets lucky and the consistency guarantees of the hardware memory model are greater than or equal to those of the Java memory model.  
			When this happens the JVM simply inserts a no op instead of an actual memory barrier.  
			For example, the consistency guarantees of the x86 and SPARC memory models are strong enough to eliminate the need for a memory barrier when reading a volatile variable.
			Remember the explicit unidirectional memory barrier we saw for the read method of WriterReader on <span style="font-weight:bold; color:red">non x86</span>?
			Well, the generated assembly instructions for the read method on an x86 and SPARC have <i>no</i> memory barrier.
		</p>
		<div class="code">
			$ java -XX:+UnlockDiagnosticVMOptions -XX:PrintAssemblyOptions=hsdis-print-bytes -XX:CompileCommand=print,WriterReader.read WriterReader
		</div>
<br/>
<table>
<tr>
<td>
&nbsp;&nbsp;WriterReader.read on x86
</td>
<td>
&nbsp;&nbsp;WriterReader.read on SPARC
</td>
</tr>
<tr>
<td valign="top"> 		
<pre>

  0x018a1d97: push   %ebp               ;...55
  0x018a1d98: mov    %esp,%ebp          ;...8bec
  0x018a1d9a: sub    $0x18,%esp         ;...83ec18
  0x018a1d9d: mov    $0x95ba53e0,%eax   ;...b8e053ba 95
                                        ;   {oop()}
  0x018a1da2: movsbl 0x14c(%eax),%eax   ;...0fbe804c 010000
  0x018a1da9: cmp    $0x0,%eax          ;...83f800
  0x018a1dac: je     0x018a1dc7         ;...0f841500 0000
  0x018a1db2: mov    $0x95ba53e0,%eax   ;...b8e053ba 95
                                        ;   {oop()}
  0x018a1db7: mov    0x148(%eax),%eax   ;...8b804801 0000
  0x018a1dbd: mov    %ebp,%esp          ;...8be5
  0x018a1dbf: pop    %ebp               ;...5d
</pre>
</td>
<td>
<pre>

  0xfa8ece60: save  %sp, -72, %sp       ;...9de3bfb8
  0xfa8ece64: sethi  %hi(0xb61f9000), %l1  ;...232d87e4
  0xfa8ece68: add  %l1, 0x3d8, %l1	! 'WriterReader'
  0xfa8ece6c: ldub  [ %l1 + 0x154 ], %l0  ;...e00c6154
  0xfa8ece70: cmp  %l0, 0               ;...80a42000
  0xfa8ece74: be,pn   %icc, 0xfa8ece8c  ;...02400006
  0xfa8ece78: ld  [ %l1 + 0x150 ], %i0  ;...f0046150
  0xfa8ece7c: sethi  %hi(0xff3fc000), %l0  ;...213fcff0
  0xfa8ece80: ld  [ %l0 ], %g0          ;...c0042000
  0xfa8ece84: ret                       ;...81c7e008
  0xfa8ece88: restore                   ;...81e80000
  0xfa8ece8c: b  %icc, 0xfa8ece7c       ;...104ffffc
  0xfa8ece90: mov  -1, %i0              ;...b0103fff
</pre>
</td>
</tr>
</table>	
		<p>
			On both architectures the volatile read operations are not paired with a memory barrier.
			In other words the only performance penalty for a volatile read on an x86 or SPARC is a minor loss of code motion optimization opportunities -
			the instruction itself is no different than an ordinary read.
		</p>
		<p>
			Unidirectional memory barriers are naturally less expensive than bidirectional ones.
			The JVM will avoid a bidirectional memory barrier when it knows a unidirectional one is sufficient.
			The first example in this article demonstrated this.  
			We saw that the read operations in WriterReader were chased with an explicit unidirectional memory barrier.
			If the read operations in WriterReader were chased with an explicit bidirectional memory barrier the program would be just as correct, but at a greater cost.
		</p>
		<p>
			On a uni-processor system the JVM can insert a no op for <i>all</i> memory barriers because memory operations are already serialized.  
			The following instructions were captured from a runtime compilation of the write method of the WriterReader class using a VMWare workstation 
			image in uni-processor mode.
			Neither write operation is chased with a memory barrier.
  		</p>
		<div class="code">
			$ java -XX:+UnlockDiagnosticVMOptions -XX:PrintAssemblyOptions=hsdis-print-bytes -XX:CompileCommand=print,WriterReader.write WriterReader
		</div> 
<pre>
  0x00f78017: push   %ebp               ;...55
  0x00f78018: mov    %esp,%ebp          ;...8bec
  0x00f7801a: sub    $0x18,%esp         ;...83ec18
  0x00f7801d: mov    $0x95ba53c0,%esi   ;...bec053ba 95
  0x00f78022: mov    $0x2a,%edi         ;...bf2a0000 00
  0x00f78027: mov    %edi,0x148(%esi)   ;...89be4801 0000
  
<span style="font-weight:bold">  No Memory Barrier</span>

  0x00f78030: mov    $0x1,%edi          ;...bf010000 00
  0x00f78035: mov    %edi,%ebx          ;...8bdf
  0x00f78037: mov    %bl,0x14c(%esi)    ;...889e4c01 0000

<span style="font-weight:bold">  No Memory Barrier</span>

  0x00f78040: mov    %ebp,%esp          ;...8be5
  0x00f78042: pop    %ebp               ;...5d
</pre>
		<h3>Conclusion</h3>
		<p>
			Memory barriers are a complex and expensive necessity for a multi-threaded programs.
			They come in many flavors.
			Some are explicit, others are implicit.
			Some are bidirectional, others are unidirectional.
			The JVM uses this array of choices to efficiently honor the Java memory model across all platforms.
		</p>
		<h3>Acknowlegements</h3>
		<p>
			Thanks to Christian Thalinger of Sun Microsystems for access to a SPARC workstation. 
		</p>		
		<h3>Reference Material</h3>
		<ul>
			<li><a href="http://www.amazon.com/Java-Concurrency-Practice-Brian-Goetz/dp/0321349601" target="new">Java Concurrency in Practice</a> by <a href="http://www.briangoetz.com/" target="new">Brian Goetz</a></li>
			<li><a href="http://g.oswego.edu/dl/jmm/cookbook.html" target="new">JSR-133 Cookbook</a> by Doug Lea</li>
		</ul>
		<h3>About the Author </h3>
		<p>
			<a href="http://notdennisbyrne.blogspot.com/">Dennis Byrne</a> is a senior software engineer for
			<a href="http://drwholdings.com/">DRW Trading</a>, a proprietary trading firm and liquidity provider.  
			He is a writer, presenter and active member of the open source community.
		</p>
	</body>
</html>