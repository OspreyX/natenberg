<html>
	<head>
		<title>Memory Barriers and the JVM</title>
		<style>
			.code{
				background-color: #CCCCCC;
				padding: 10px
			}
		</style>
	</head>
	<body>
		<h1>Memory Barriers and the JVM</h1>
		<p>
			Memory barriers, or fences, are a set of processor instructions used to apply ordering limitations on memory operations.  		
			This article explains the impact memory barriers have on the determinism of multi-threaded programs.
			We'll look at how memory barriers relate to JVM concurrency constructs such as volatile, synchronized and atomic conditionals. 
			It is assumed the reader has a solid understanding of these concepts and the Java memory model as a whole.
			This is not an article about mutual exclusion, parallelism or atomicity per se.
			Memory barriers are used to achieve an equally important element of concurrent programming called visibility.
		</p>
		<h3>What Are Memory Barriers?</h3>
		<p>
			The costs of memory latency have pushed processors to reorder and cache memory operations.
			A trip to main memory costs hundreds of clock cycles on commodity hardware.
			Processors use caching to decrease latency costs of memory operations by orders of magnitude.
			These caches introduce a substantial visibility delay because the value of each write operation does not immediately "write through" to main memory.
			The processor instead places this operation in a buffer and is obligated to "write back" the value later.
			Buffers are often misunderstood as queues; they are not.
			Pending memory operations are not necessarily performed in the order in which they are fed to the processor.
			This opens the door for many optimizations when data is immutable and/or confined to the scope of one thread.  
		</p>
		<p>
			Combining these optimizations with symmetric multi-processing and shared mutable state is a nightmare.
			A program can behave non-deterministically when memory operations on shared mutable state are re-ordered.  
			It is possible for a thread to write values that become visible to another thread in an order that is inconsistent 
			with the order in which they were written.
			A well placed memory barrier prevents this problem by forcing the processor to serialize pending memory operations.
			The performance implications of memory barriers are beyond the scope of this article.
		</p>
		<h3>Memory Barriers As Protocols</h3>
		<p>
			Memory barriers are not directly exposed by the JVM; 
			instead they are inserted into the instruction sequence by the JVM in order to uphold the semantics of language level concurrency primitives.
			Let's look at the source code and assembly instructions of some simple Java programs to see how. 
			This requires the latest OpenJDK release or a new version of HotSpot, update 14 or above.
			A disassembler plugin is also required. The Kenai project <a href="http://kenai.com/projects/base-hsdis/downloads" target="new">has binaries</a>
			for Solaris, Linux and BSD.  The <a href="http://hg.openjdk.java.net/jdk7/hotspot/hotspot/file/tip/src/share/tools/hsdis/" target="new">hsdis</a>
			plugin is an alternative that can be built from source for Windows.
		</p>
		<!--div class="code">
		The following works for Linux.
			$ wget http://kenai.com/projects/base-hsdis/downloads/download/linux-hsdis-i386.so<br/>
			$ cp linux-hsdis-i386.so /usr/lib/jvm/java-6-openjdk/jre/lib/i386/server/<br/>
			$ cp linux-hsdis-i386.so /usr/lib/jvm/java-6-openjdk/jre/lib/i386/client/<br/>
		</div-->
		<p>
			Let's begin a crash course in memory barriers with the Dekker's algorithm, 
			a protocol used to coordinate access to a shared resource by two threads.
			Try not to focus on the finer details of this algorithm.
			Just observe that both threads communicate via three volatile variables.  
			Each thread attempts to enter the critical section on the first line of code by signaling an intent to do so.
			If a thread observes a conflict on line three (both threads have signaled intent) the conflict is resolved by turn taking.
			Only one thread can ever access the critical section at a time.		
		</p>
		<table>
			<tr>
				<td>
					Code run by the first thread:
				</td>
				<td style="padding-left:40px">
					Code run by the second thread:
				</td>				
			</tr>
			<tr>
				<td>
<pre>
 1    intentFirst = true;
 2
 3    while (intentSecond)
 4    	if (turn != 0) {
 5    		intentFirst = false;
 6    		while (turn != 0) {}
 7    		intentFirst = true;
 8    	}
 9
10    criticalSection();
11
12    turn = 1;
13    intentFirst = false;
</pre>				
				</td>
				<td style="padding-left:40px">
<pre>
intentSecond = true;

while (intentFirst)
	if (turn != 1) {
		intentSecond = false;
		while (turn != 1) {}
		intentSecond = true;
	}

criticalSection();

turn = 0;
intentSecond = false;
</pre>				
				</td>
			</tr>
		</table>
		<p>
			Why are memory barriers important to Dekker's algorithm?
			Because compiler and hardware optimizations will break this code without them.
			Consider two small blocks of code above.
			Lines three and four represent two successive load operations.
			Each thread checks to see if the other has signaled an intent to enter the critical section
			<i>and then</i> each thread checks to see who's turn it is.
			Lines 12 and 13 represent two successive write operations.
			Each thread gives the other it's "turn" <i>and then</i> on each thread withdraws intent to enter the critical section.
			Consider the point of view of a reading thread.
			A reading thread should never expect to observe the other threads write to the turn variable before the other thread's withdrawal of intent.
			Without the volatile modifier on these variables this indeed can happen.
			For example, without the volatile modifier the second thread could observe the write to intentFirst (last line) before the write to turn (second to last line). 
			The keyword volatile prevents this problem because it establishes a <i>happens before</i> relationship between the write to the turn variable and the write to intentFirst.
			The compiler cannot re-order these write operations and if necessary it must forbid the processor from doing so.
			A peek under the hood shows how.
		</p>
		<!--div class="code">
			$ java -XX:+UnlockDiagnosticVMOptions -XX:PrintAssemblyOptions=hsdis-print-bytes -XX:CompileCommand=print,WriterReader.read WriterReader
		</div-->
		<p>
			The two successive load operations on lines three and four translate to the instructions below.
			These instructions were captured on multi-processing Itanium hardware. 
		</p>
<pre>
49  0x2000000001de819c:             adds r37=597,r36;;  ;...84112554
50  <b>0x2000000001de81a0: [MMI]       ld1.acq r38=[r37];;  ;...0b30014a a010</b>
51  0x2000000001de81a6:             nop.m 0x0     ;...00000002 00c0
52  0x2000000001de81ac:             sxt1 r38=r38;;  ;...00513004
53  0x2000000001de81b0: [MIB]       cmp4.eq p0,p6=0,r38  ;...1100004c 8639
54  0x2000000001de81b6:             nop.i 0x0     ;...00000002 0003
55  0x2000000001de81bc:       (p06) br.cond.dpnt.many 0x2000000001de8220;;

...

78  0x2000000001de8220: [MMI]       adds r38=592,r36  ;...09304149 0421
79  0x2000000001de8226:             nop.m 0x0     ;...00000002 0000
80  0x2000000001de822c:             nop.i 0x0;;   ;...00040000
81  <b>0x2000000001de8230: [MMI]       ld4.acq r41=[r38]  ;...0948014c b010</b>
82  0x2000000001de8236:             nop.m 0x0     ;...00000002 0000
83  0x2000000001de823c:             nop.i 0x0;;   ;...00040000
84                                                ; OopMap{gr38=Derived_oop_gr36 gr37=Derived_oop_gr36 gr36=Oop off=288}
85                                                ;*ifeq
86                                                ; - com.drw.membar.FirstThread::protocol@13
87  0x2000000001de8240: [MMI]       ld8 r31=[r5]  ;...09f8000a 1810
88                                                ;   {poll}
89  0x2000000001de8246:             nop.m 0x0     ;...00000002 0000
90  0x2000000001de824c:             nop.i 0x0;;   ;...00040000
91  0x2000000001de8250: [MIB]       cmp4.eq p6,p0=0,r41  ;...11300052 8039
92  0x2000000001de8256:             nop.i 0x0     ;...00000002 0003
93  0x2000000001de825c:       (p06) br.cond.dptk.many 0x2000000001de8310;;
</pre>	
		<p>
			This short stream of instructions tells a long story.
			The reads of both volatile variables are on lines 50 and 81.  
			The Java memory model guarantees the JVM will deliver both reads to the processor in program order - 
			but this alone would not be enough because the processor is still free to perform these operations out of order.
			To uphold the consistency guarantees of the Java memory model the JVM creates a memory barrier via an explicit ld.acq instruction.
			The ld.acq, or "load acquire", instruction is an ordered load instruction for the Itanium instruction set.</span>
			Notice that this instruction affects loads, not stores.  
			A memory barrier that enforces ordering limitations on reads <i>or</i> writes is said to be unidirectional.
			A memory barrier that enforces ordering limitations on reads <i>and</i> writes is said to be bidirectional, or, a full fence.  
			The ld.acq instruction is a unidirectional memory barrier.
		</p>
		<p>
			Consistency is a two way street.
			How useful is it for the reader thread to insert a memory barrier between both reads if the writer thread does not separate both writes with one as well?
			In order for threads to communicate they must <i>all</i> obey the protocol; just like nodes on a network, or people on a team.
			If one thread breaks formation than the efforts of all other threads are rendered useless.
			We should expect to see memory barriers in the assembly instructions for the write method of the WriterReader.
		</p>
		<!--div class="code">
			$ java -XX:+UnlockDiagnosticVMOptions -XX:PrintAssemblyOptions=hsdis-print-bytes -XX:CompileCommand=print,WriterReader.write WriterReader
		</div-->	
<pre>
57  0x2000000001de81c0: [MMI]       adds r37=592,r36;;  ;...0b284149 0421
58<b>  0x2000000001de81c6:             st4.rel [r37]=r39  ;...00389560 2380</b>
59  0x2000000001de81cc:             adds r36=596,r36;;  ;...84112544
60<b>  0x2000000001de81d0: [MMI]       st1.rel [r36]=r0  ;...09000048 a011</b>
61<b>  0x2000000001de81d6:             mf            ;...00000044 0000</b>
62  0x2000000001de81dc:             nop.i 0x0;;   ;...00040000
63  0x2000000001de81e0: [MII]       mov r12=r33   ;...00600042 0021
64  0x2000000001de81e6:             mov.ret b0=r35,0x2000000001de81e0
65                                                ;...00181580 0300
66  0x2000000001de81ec:             mov.i ar.pfs=r34  ;...00aa0220
67  0x2000000001de81f0: [MMI]       mov r6=r32    ;...09300040 0021
</pre>
		<p>
			Here we can see both write operations are paired with explicit memory barriers on lines 58 and 60.
			The st.rel, or "store release", instruction is an ordered store instruction for the Itanium instruction set.
			Like the ld.acq instruction it is a unidirectional memory barrier.
			This completes both sides of the protocol because each write operation <i>happens before</i> subsequent memory operations.
		</p>		
		<h3>Memory Barriers Are Hardware Specific</h3>
		<p>
			This article does not aim to be a comprehensive overview of all memory barriers.
			This would be a monumental task.
			But it is important though to appreciate the fact that these instructions vary considerably across different hardware architectures.
			Below is what the write method of WriterReader translates to on a multi-processing Intel Xeon E5410 and a SPARC workstation.
			All remaining assembly instruction sequences in this article were captured on an Intel Xeon unless specified otherwise.
		</p>
<table>
<tr>
<td>
The WriterReader.write method on x86.
</td>
<td>
The WriterReader.write method on SPARC.
</td>
</tr>
<tr>
<td valign="top">
<pre>

  0x00f78017: push   %ebp               ;...55
  0x00f78018: mov    %esp,%ebp          ;...8bec
  0x00f7801a: sub    $0x18,%esp         ;...83ec18
  0x00f7801d: mov    $0x95ba53c0,%esi   ;...bec053ba 95
  0x00f78022: mov    $0x2a,%edi         ;...bf2a0000 00
  0x00f78027: mov    %edi,0x148(%esi)   ;...89be4801 0000
  <span style="font-weight:bold">0x00f7802d: mfence                    ;...0faef0</span>
  0x00f78030: mov    $0x1,%edi          ;...bf010000 00
  0x00f78035: mov    %edi,%ebx          ;...8bdf
  0x00f78037: mov    %bl,0x14c(%esi)    ;...889e4c01 0000
  <span style="font-weight:bold">0x00f7803d: mfence                    ;...0faef0</span>
  0x00f78040: mov    %ebp,%esp          ;...8be5
  0x00f78042: pop    %ebp               ;...5d
</pre>
</td>
<td>
<pre>

  0xfa8ecea0: save  %sp, -72, %sp       ;...9de3bfb8
  0xfa8ecea4: sethi  %hi(0xb61f9000), %l1  ;...232d87e4
  0xfa8ecea8: add  %l1, 0x3d8, %l1	! 'WriterReader'
  0xfa8eceac: mov  0x2a, %l0            ;...a010202a
  0xfa8eceb0: st  %l0, [ %l1 + 0x150 ]  ;...e0246150
  0xfa8eceb4: mov  1, %l2               ;...a4102001
  0xfa8eceb8: stb  %l2, [ %l1 + 0x154 ]  ;...e42c6154
  <span style="font-weight:bold">0xfa8ecebc: membar  #StoreLoad        ;...8143e002</span>
  0xfa8ecec0: sethi  %hi(0xff3fc000), %l0  ;...213fcff0
  0xfa8ecec4: ld  [ %l0 ], %g0          ;...c0042000
                                        ;   {poll_return}  
  0xfa8ecec8: ret                       ;...81c7e008
  0xfa8ececc: restore                   ;...81e80000
</pre>
</td>
</tr>
</table>
		<p>
			On the x86 the JVM chases both write operations with an mfence instruction, an explicit bidirectional memory barrier.  
			On the SPARC the JVM shows a little more trust with a single membar instruction.
		</p>
		<h3>Memory Barriers Can Be Explicit or Implicit</h3>
		<p>
			Explicit fence instructions are not the only way to serialize memory operations. 
			Let's switch gears to the Counter class to see an example.  
		</p>
		<pre>
    class Counter{
	
        static int counter = 0;
	
        public static void main(String[] _){
            for(int i = 0; i < 100000; i++)
                inc();
        }
	
        static synchronized void inc(){ counter += 1; }
	
    }		
		</pre>
		<p>
			The Counter class performs a classic read-modify-write operation.  
			The static counter field is not volatile because all three operations must be observed atomically.  
			For this reason the inc method of the Counter class is synchronized.
			We can compile the Counter class and observe the generated assembly instructions for the synchronized inc method with the following command. 
			The Java memory model guarantees the same visibility semantics for exiting of synchronized regions as it does for
			volatile memory operations, so we should expect to see another memory barrier.
		</p>
		<div class="code">
		$ java -XX:+UnlockDiagnosticVMOptions -XX:PrintAssemblyOptions=hsdis-print-bytes -XX:-UseBiasedLocking -XX:CompileCommand=print,Counter.inc Counter
		</div>
		<pre>
   1: push   %ebp               ;...55
   2: mov    %esp,%ebp          ;...8bec
   3: sub    $0x28,%esp         ;...83ec28
   4: mov    $0x95ba5408,%esi   ;...be0854ba 95
   5: lea    0x10(%esp),%edi    ;...8d7c2410
   6: mov    %esi,0x4(%edi)     ;...897704
   7: mov    (%esi),%eax        ;...8b06
   8: or     $0x1,%eax          ;...83c801
   9: mov    %eax,(%edi)        ;...8907
  <span style="font-weight:bold">10: lock cmpxchg %edi,(%esi)  ;...f00fb13e</span>
  11: je     0x011f2dda         ;...0f841000 0000
  12: sub    %esp,%eax          ;...2bc4
  13: and    $0xfffff003,%eax   ;...81e003f0 ffff
  14: mov    %eax,(%edi)        ;...8907
  15: jne    0x011f2e11         ;...0f853700 0000
  16: mov    $0x95ba52b8,%eax   ;...b8b852ba 95
  17: mov    0x148(%eax),%esi   ;...8bb04801 0000
  <span style="font-weight:bold">18: inc    %esi               ;...46</span>
  19: mov    %esi,0x148(%eax)   ;...89b04801 0000
  20: lea    0x10(%esp),%eax    ;...8d442410
  21: mov    (%eax),%esi        ;...8b30
  22: test   %esi,%esi          ;...85f6
  23: je     0x011f2e07         ;...0f840d00 0000
  24: mov    0x4(%eax),%edi     ;...8b7804
  <span style="font-weight:bold">25: lock cmpxchg %esi,(%edi)  ;...f00fb137</span>
  26: jne    0x011f2e1f         ;...0f851800 0000
  27: mov    %ebp,%esp          ;...8be5
  28: pop    %ebp               ;...5d
		</pre>
		<p>
		  To no surprise the number of instructions generated by synchronized is more than volatile.  The increment is found on line 18 but 
		  at no point does the JVM insert an explicit memory barrier.  Instead, the JVM has killed two birds with one stone using a lock prefixed cmpxchg instruction 
		  on lines 10 and 25.  The semantics of cmpxchg are beyond the scope of this article.  
		  What's relevant is that 'lock cmpxchg' not only performs the write operation atomically - it also flushes pending read and write operations.  
		  The write operation will now become visible before all subsequent memory operations.
		  If we refactor and run the Counter class to use java.util.concurrent.atomic.AtomicInteger we can observe this same trick.
		</p>
<pre>
    import java.util.concurrent.atomic.AtomicInteger;
	
    class Counter{
	
        static AtomicInteger counter = new AtomicInteger(0);
	
        public static void main(String[] args){
            for(int i = 0; i < 1000000; i++)
                counter.incrementAndGet(); 
        }
	
    }
</pre>		
		<div class="code">
		$ java -XX:+UnlockDiagnosticVMOptions -XX:PrintAssemblyOptions=hsdis-print-bytes -XX:CompileCommand=print,*AtomicInteger.incrementAndGet Counter
		</div>
<pre>
   1: push   %ebp               ;...55
   2: mov    %esp,%ebp          ;...8bec
   3: sub    $0x38,%esp         ;...83ec38
   4: jmp    0x043cb20a         ;...e9080000 00
   5: xchg   %ax,%ax            ;...6690
   6: test   %eax,0xb788d100    ;...850500d1 88b7
   7: mov    0x8(%ecx),%eax     ;...8b4108
   8: mov    %eax,%esi          ;...8bf0
   9: inc    %esi               ;...46
  10: mov    $0x9a3f03d0,%edi   ;...bfd0033f 9a
  11: mov    0x160(%edi),%edi   ;...8bbf6001 0000
  12: mov    %ecx,%edi          ;...8bf9
  13: add    $0x8,%edi          ;...83c708
  <span style="font-weight:bold">14: lock cmpxchg %esi,(%edi)  ;...f00fb137</span>
  15: mov    $0x1,%eax          ;...b8010000 00
  16: je     0x043cb234         ;...0f840500 0000
  17: mov    $0x0,%eax          ;...b8000000 00
  18: cmp    $0x0,%eax          ;...83f800
  19: je     0x043cb204         ;...74cb
  20: mov    %esi,%eax          ;...8bc6
  21: mov    %ebp,%esp          ;...8be5
  22: pop    %ebp               ;...5d
</pre>		
		<p>
			Again we see the write operation being combined with a lock prefix on line 14.  This insures the new 
			value of the variable will become visible to other threads before all subsequent memory operations.
		</p>		
		<h3>Memory Barriers Can Be Avoided</h3>
		<p>
			The JVM is very good at eliminating unnecessary memory barriers.
			Often it gets lucky and the consistency guarantees of the hardware memory model are greater than or equal to those of the Java memory model.  
			When this happens the JVM simply inserts a no op instead of an actual memory barrier.  
			For example, the consistency guarantees of the x86 and SPARC memory models are strong enough to eliminate the need for a memory barrier when reading a volatile variable.
			Remember the explicit unidirectional memory barrier we saw for the read method of WriterReader on Itanium?
			Well, the generated assembly instructions for the read method on an x86 and SPARC have <i>no</i> memory barrier.
		</p>
		<div class="code">
			$ java -XX:+UnlockDiagnosticVMOptions -XX:PrintAssemblyOptions=hsdis-print-bytes -XX:CompileCommand=print,WriterReader.read WriterReader
		</div>
<br/>
<table>
<tr>
<td>
&nbsp;&nbsp;WriterReader.read on x86
</td>
<td>
&nbsp;&nbsp;WriterReader.read on SPARC
</td>
</tr>
<tr>
<td valign="top"> 		
<pre>

  0x018a1d97: push   %ebp               ;...55
  0x018a1d98: mov    %esp,%ebp          ;...8bec
  0x018a1d9a: sub    $0x18,%esp         ;...83ec18
  0x018a1d9d: mov    $0x95ba53e0,%eax   ;...b8e053ba 95
                                        ;   {oop()}
  0x018a1da2: movsbl 0x14c(%eax),%eax   ;...0fbe804c 010000
  0x018a1da9: cmp    $0x0,%eax          ;...83f800
  0x018a1dac: je     0x018a1dc7         ;...0f841500 0000
  0x018a1db2: mov    $0x95ba53e0,%eax   ;...b8e053ba 95
                                        ;   {oop()}
  0x018a1db7: mov    0x148(%eax),%eax   ;...8b804801 0000
  0x018a1dbd: mov    %ebp,%esp          ;...8be5
  0x018a1dbf: pop    %ebp               ;...5d
</pre>
</td>
<td>
<pre>

  0xfa8ece60: save  %sp, -72, %sp       ;...9de3bfb8
  0xfa8ece64: sethi  %hi(0xb61f9000), %l1  ;...232d87e4
  0xfa8ece68: add  %l1, 0x3d8, %l1	! 'WriterReader'
  0xfa8ece6c: ldub  [ %l1 + 0x154 ], %l0  ;...e00c6154
  0xfa8ece70: cmp  %l0, 0               ;...80a42000
  0xfa8ece74: be,pn   %icc, 0xfa8ece8c  ;...02400006
  0xfa8ece78: ld  [ %l1 + 0x150 ], %i0  ;...f0046150
  0xfa8ece7c: sethi  %hi(0xff3fc000), %l0  ;...213fcff0
  0xfa8ece80: ld  [ %l0 ], %g0          ;...c0042000
  0xfa8ece84: ret                       ;...81c7e008
  0xfa8ece88: restore                   ;...81e80000
  0xfa8ece8c: b  %icc, 0xfa8ece7c       ;...104ffffc
  0xfa8ece90: mov  -1, %i0              ;...b0103fff
</pre>
</td>
</tr>
</table>	
		<p>
			On both architectures the volatile read operations are not paired with a memory barrier.
			In other words the only performance penalty for a volatile read on an x86 or SPARC is a minor loss of code motion optimization opportunities -
			the instruction itself is no different than an ordinary read.
		</p>
		<p>
			Unidirectional memory barriers are naturally less expensive than bidirectional ones.
			The JVM will avoid a bidirectional memory barrier when it knows a unidirectional one is sufficient.
			The first example in this article demonstrated this.  
			We saw that the read operations in WriterReader were chased with an explicit unidirectional memory barrier.
			If the read operations in WriterReader were chased with an explicit bidirectional memory barrier the program would be just as correct, but at a greater cost.
		</p>
		<p>
			On a uni-processor system the JVM can insert a no op for <i>all</i> memory barriers because memory operations are already serialized.  
			The following instructions were captured from a runtime compilation of the write method of the WriterReader class using a VMWare workstation 
			image in uni-processor mode.
			Neither write operation is chased with a memory barrier.
  		</p>
		<div class="code">
			$ java -XX:+UnlockDiagnosticVMOptions -XX:PrintAssemblyOptions=hsdis-print-bytes -XX:CompileCommand=print,WriterReader.write WriterReader
		</div> 
<pre>
  0x00f78017: push   %ebp               ;...55
  0x00f78018: mov    %esp,%ebp          ;...8bec
  0x00f7801a: sub    $0x18,%esp         ;...83ec18
  0x00f7801d: mov    $0x95ba53c0,%esi   ;...bec053ba 95
  0x00f78022: mov    $0x2a,%edi         ;...bf2a0000 00
  0x00f78027: mov    %edi,0x148(%esi)   ;...89be4801 0000
  
<span style="font-weight:bold">  No Memory Barrier</span>

  0x00f78030: mov    $0x1,%edi          ;...bf010000 00
  0x00f78035: mov    %edi,%ebx          ;...8bdf
  0x00f78037: mov    %bl,0x14c(%esi)    ;...889e4c01 0000

<span style="font-weight:bold">  No Memory Barrier</span>

  0x00f78040: mov    %ebp,%esp          ;...8be5
  0x00f78042: pop    %ebp               ;...5d
</pre>
		<h3>Conclusion</h3>
		<p>
			Memory barriers are a complex and expensive necessity for a multi-threaded programs.
			They come in many flavors.
			Some are explicit, others are implicit.
			Some are bidirectional, others are unidirectional.
			The JVM uses this array of choices to efficiently honor the Java memory model across all platforms.
		</p>
		<h3>Acknowlegements</h3>
		<p>
			Thanks to Christian Thalinger of Sun Microsystems for access to a SPARC workstation. 
		</p>		
		<h3>Reference Material</h3>
		<ul>
			<li><a href="http://www.amazon.com/Java-Concurrency-Practice-Brian-Goetz/dp/0321349601" target="new">Java Concurrency in Practice</a> by <a href="http://www.briangoetz.com/" target="new">Brian Goetz</a></li>
			<li><a href="http://g.oswego.edu/dl/jmm/cookbook.html" target="new">JSR-133 Cookbook</a> by Doug Lea</li>
			<li><a href="http://en.wikipedia.org/wiki/Dekker%27s_algorithm" target="new">Dekker's Algorithm</a></li>
		</ul>
		<h3>About the Author </h3>
		<p>
			<a href="http://notdennisbyrne.blogspot.com/">Dennis Byrne</a> is a senior software engineer for
			<a href="http://drwholdings.com/">DRW Trading</a>, a proprietary trading firm and liquidity provider.  
			He is a writer, presenter and active member of the open source community.
		</p>
	</body>
</html>